# üìä An√°lisis de Concurrencia - Sistema OBYRA

**Fecha**: 2 de Noviembre de 2025
**Versi√≥n**: 1.0
**Estado**: An√°lisis Completo

---

## üìã Resumen Ejecutivo

El sistema OBYRA puede manejar **~200-300 usuarios concurrentes activos** bajo carga normal, con picos de hasta **~500-600 usuarios** durante per√≠odos cortos. Los principales limitantes son:

1. **Gunicorn Workers**: 8 requests simult√°neas (cuello de botella principal)
2. **PostgreSQL Pool**: 30 conexiones m√°ximas
3. **Rate Limiting**: Var√≠a por endpoint (3-100 req/min)

**Recomendaci√≥n**: El sistema est√° bien configurado para equipos medianos (50-100 usuarios activos diarios), pero requerir√° escalamiento horizontal para empresas grandes (>200 usuarios activos simult√°neos).

---

## üîç Componentes Analizados

### 1. Nginx - Reverse Proxy

**Archivo**: `nginx/nginx.conf`

| Par√°metro | Valor | Impacto en Concurrencia |
|-----------|-------|------------------------|
| `worker_processes` | auto | Se ajusta seg√∫n CPU cores (t√≠picamente 2-8) |
| `worker_connections` | 1024 | **1,024 conexiones por worker** |
| `keepalive` | 32 | Reutiliza 32 conexiones al backend |

**Capacidad Te√≥rica de Nginx**:
```
Total = worker_processes √ó worker_connections
Ejemplo (4 cores): 4 √ó 1024 = 4,096 conexiones simult√°neas
```

**Rate Limiting en Nginx**:
```nginx
limit_req_zone $binary_remote_addr zone=login_limit:10m rate=5r/m;
limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/s;
limit_req_zone $binary_remote_addr zone=general_limit:10m rate=50r/s;
```

- **Login**: 5 requests/minuto por IP (adicional al rate limit de Flask)
- **API**: 100 requests/segundo por IP
- **General**: 50 requests/segundo por IP

**Conclusi√≥n**: Nginx NO es un cuello de botella. Puede manejar miles de conexiones simult√°neas.

---

### 2. Gunicorn - Application Server

**Archivo**: `Dockerfile:100`

```bash
gunicorn --bind 0.0.0.0:5000 \
  --workers 4 \
  --threads 2 \
  --timeout 120
```

| Par√°metro | Valor | Significado |
|-----------|-------|-------------|
| `workers` | 4 | 4 procesos independientes de Python |
| `threads` | 2 | 2 threads por worker |
| `timeout` | 120s | Request timeout de 2 minutos |

**Capacidad de Gunicorn**:
```
Requests Concurrentes = workers √ó threads
                     = 4 √ó 2 = 8 requests simult√°neas
```

**‚ö†Ô∏è CUELLO DE BOTELLA PRINCIPAL**

Con solo 8 requests concurrentes, este es el **limitante principal** del sistema.

**F√≥rmula de Workers Recomendados** (seg√∫n documentaci√≥n de Gunicorn):
```
workers = (2 √ó CPU_cores) + 1
```

Para un servidor con 4 cores:
```
workers = (2 √ó 4) + 1 = 9 workers
```

**C√°lculo de Throughput** (requests por segundo):

Asumiendo request promedio de 200ms:
```
Throughput = (requests concurrentes) / (tiempo promedio request)
           = 8 / 0.2 seg
           = 40 requests/segundo
```

Para requests m√°s lentos (500ms):
```
Throughput = 8 / 0.5 = 16 requests/segundo
```

**Usuarios Concurrentes Soportados**:

Un usuario activo genera ~2-5 requests por minuto (navegaci√≥n normal).

```
Usuarios = Throughput √ó 60 / requests_por_usuario_min
        = 40 √ó 60 / 3
        = ~800 usuarios activos (con requests r√°pidos)

Realista (500ms promedio):
        = 16 √ó 60 / 3
        = ~320 usuarios activos
```

**Conclusi√≥n**: Con 4 workers √ó 2 threads, el sistema soporta **200-400 usuarios concurrentes activos** dependiendo de la latencia de las operaciones.

---

### 3. PostgreSQL - Base de Datos

**Archivo**: `app.py:140-155`

```python
app.config["SQLALCHEMY_ENGINE_OPTIONS"] = {
    "pool_size": 10,           # Conexiones en el pool
    "max_overflow": 20,        # Conexiones adicionales
    "pool_timeout": 30,        # Timeout para obtener conexi√≥n
    "pool_recycle": 1800,      # Reciclar cada 30 min
    "pool_pre_ping": True,     # Health check
}
```

| Par√°metro | Valor | Significado |
|-----------|-------|-------------|
| `pool_size` | 10 | 10 conexiones permanentes en el pool |
| `max_overflow` | 20 | Hasta 20 conexiones adicionales bajo carga |
| **Total M√°ximo** | **30** | **30 conexiones concurrentes m√°ximo** |

**Relaci√≥n con Gunicorn**:

Cada worker de Gunicorn puede necesitar 1-2 conexiones a PostgreSQL.

```
Max Conexiones Necesarias = workers √ó threads √ó 1.5 (factor de seguridad)
                          = 4 √ó 2 √ó 1.5
                          = 12 conexiones

Disponibles: 30 conexiones
Utilizadas: ~12 conexiones bajo carga normal
Margen: 18 conexiones (150% de headroom) ‚úÖ Bien configurado
```

**Timeout de Query**: 30 segundos (`statement_timeout=30000ms`)

**Conclusi√≥n**: PostgreSQL NO es un cuello de botella. El pool es suficiente para la configuraci√≥n actual de Gunicorn.

---

### 4. Redis - Cache & Sessions

**Archivo**: `docker-compose.yml:39`

```bash
redis-server --appendonly yes \
  --maxmemory 512mb \
  --maxmemory-policy allkeys-lru
```

| Par√°metro | Valor | Significado |
|-----------|-------|-------------|
| `maxmemory` | 512MB | M√°ximo de memoria RAM para cache |
| `maxmemory-policy` | allkeys-lru | Evict menos usados cuando se llena |

**Capacidad de Redis**:

512MB es suficiente para:
- **~50,000 sessions** (10KB cada una)
- **~500,000 entradas de cache** peque√±as (1KB cada una)
- **~100,000 rate limit counters**

**Throughput de Redis**: >100,000 ops/segundo (t√≠pico en un solo core)

**Conclusi√≥n**: Redis NO es un cuello de botella. Puede manejar f√°cilmente la carga del sistema.

---

### 5. Celery - Background Tasks

**Archivo**: `docker-compose.yml:142`

```bash
celery -A celery_app worker --loglevel=info --concurrency=4
```

| Par√°metro | Valor | Significado |
|-----------|-------|-------------|
| `concurrency` | 4 | 4 tareas en paralelo |

**Capacidad de Celery**:
- 4 tareas pesadas ejecut√°ndose simult√°neamente
- Tareas en cola esperan a que se libere un worker

**Uso T√≠pico**:
- Generaci√≥n de reportes PDF
- Geocodificaci√≥n de direcciones
- Env√≠o de emails
- Procesamiento de im√°genes

**Conclusi√≥n**: Celery maneja tareas as√≠ncronas adecuadamente para el tama√±o actual del sistema.

---

### 6. Rate Limiting - Flask Limiter

**Archivo**: `auth.py`, `obras.py`

#### Endpoints de Autenticaci√≥n:

| Endpoint | L√≠mite | Impacto |
|----------|--------|---------|
| POST /auth/login | 10/min | Max 10 intentos de login por minuto |
| POST /auth/register | 3/min | Max 3 registros por minuto |
| POST /auth/forgot | 5/min | Max 5 solicitudes de reset |
| POST /auth/reset/<token> | 5/min | Max 5 resets por minuto |

#### Endpoints Administrativos:

| Endpoint | L√≠mite | Impacto |
|----------|--------|---------|
| POST /auth/usuarios/integrantes | 20/min | Max 20 creaciones de usuarios/min |
| POST /auth/usuarios/cambiar_rol | 30/min | Max 30 cambios de rol/min |

#### Endpoints Cr√≠ticos de Obras:

| Endpoint | L√≠mite | Impacto |
|----------|--------|---------|
| POST /obras/eliminar/<id> | 10/min | Max 10 eliminaciones/min |
| POST /obras/api/.../bulk_delete | 20/min | Max 20 operaciones bulk/min |
| POST /obras/reiniciar-sistema | **1/min** | Operaci√≥n extremadamente destructiva |
| POST /obras/geocodificar-todas | **2/hora** | API externa costosa |

**Conclusi√≥n**: Rate limiting protege contra abuso pero limita operaciones masivas. Esto es **intencional por seguridad**.

---

## üìà Capacidad M√°xima Te√≥rica

### Escenario 1: Carga Normal (Navegaci√≥n Web)

**Asunciones**:
- Request promedio: 200ms
- Usuario genera 3 requests/minuto
- 80% de requests cacheable en Redis

**Capacidad**:
```
Throughput efectivo = 8 requests concurrentes / 0.2s = 40 req/s
Usuarios concurrentes = 40 √ó 60 / 3 = ~800 usuarios

Con cache hit (80%):
Usuarios = 800 / 0.2 (factor de cache) = ~400 usuarios activos
```

**Resultado**: **~400 usuarios concurrentes navegando activamente**

---

### Escenario 2: Carga Media (Operaciones de Base de Datos)

**Asunciones**:
- Request promedio: 500ms
- Usuario genera 5 requests/minuto
- 50% de requests requieren DB

**Capacidad**:
```
Throughput = 8 / 0.5s = 16 req/s
Usuarios = 16 √ó 60 / 5 = ~192 usuarios

Con DB overhead:
Usuarios = 192 √ó 0.8 = ~150 usuarios activos
```

**Resultado**: **~150-200 usuarios con operaciones intensivas**

---

### Escenario 3: Carga Alta (Reportes/Operaciones Pesadas)

**Asunciones**:
- Request promedio: 2 segundos (generaci√≥n de PDFs, consultas complejas)
- Usuario genera 10 requests/minuto
- 100% de requests usan DB

**Capacidad**:
```
Throughput = 8 / 2s = 4 req/s
Usuarios = 4 √ó 60 / 10 = ~24 usuarios

Con Celery offloading:
Usuarios = 24 √ó 3 (tareas async) = ~72 usuarios
```

**Resultado**: **~50-100 usuarios con operaciones muy pesadas**

---

## üö® Cuellos de Botella Identificados

### 1. üî¥ CR√çTICO - Gunicorn Workers (4 √ó 2 = 8)

**Problema**: Solo 8 requests simult√°neas es MUY BAJO para producci√≥n.

**S√≠ntomas cuando se alcanza el l√≠mite**:
- Timeouts en el navegador
- Requests en cola esperando
- Usuarios experimentan lentitud extrema

**Soluci√≥n**:
```bash
# Recomendado para servidor de 4 cores:
--workers 9 --threads 2  # 18 requests concurrentes

# Para servidor de 8 cores:
--workers 17 --threads 2  # 34 requests concurrentes
```

**Impacto de la mejora**:
```
Actual: 8 requests ‚Üí ~200-400 usuarios
Con 18 requests ‚Üí ~450-900 usuarios
Con 34 requests ‚Üí ~850-1700 usuarios
```

---

### 2. üü° MEDIO - PostgreSQL Pool (30 conexiones)

**Problema**: Si aumentas workers a 9-17, podr√≠as quedarte sin conexiones.

**Recomendaci√≥n**:
```python
# Para 9 workers √ó 2 threads = 18 concurrentes:
"pool_size": 15,
"max_overflow": 30,  # Total: 45 conexiones

# Para 17 workers √ó 2 threads = 34 concurrentes:
"pool_size": 20,
"max_overflow": 40,  # Total: 60 conexiones
```

**Nota**: PostgreSQL puede manejar 100-200 conexiones sin problema en hardware moderno.

---

### 3. üü° MEDIO - Rate Limiting Agresivo

**Problema**: Algunos rate limits son muy estrictos para uso leg√≠timo.

**Ejemplos problem√°ticos**:
- `POST /auth/register` - 3/min: Un admin registrando m√∫ltiples usuarios debe esperar
- `POST /obras/geocodificar-todas` - 2/hora: Solo 2 geocodificaciones masivas al d√≠a

**Recomendaci√≥n**:
- Implementar **rate limiting por usuario autenticado** (m√°s permisivo)
- Mantener **rate limiting por IP** (estricto) para no autenticados
- Usar diferentes l√≠mites para admin vs usuario regular

---

### 4. üü¢ BAJO - Redis Memory (512MB)

**Problema**: Puede llenarse con muchas sesiones activas.

**Capacidad actual**: ~50,000 sesiones simult√°neas

**Recomendaci√≥n**: Aumentar a 1GB si se esperan >30,000 usuarios concurrentes.

```yaml
# docker-compose.yml
command: redis-server --maxmemory 1gb --maxmemory-policy allkeys-lru
```

---

## üìä Tabla Resumen de Capacidad

| Componente | Configuraci√≥n Actual | Capacidad M√°xima | Cuello de Botella | Prioridad |
|------------|---------------------|------------------|-------------------|-----------|
| **Nginx** | 1024 conn/worker | ~4,096 conexiones | ‚ùå No | ‚úÖ OK |
| **Gunicorn** | 4 workers √ó 2 threads | **8 requests** | ‚úÖ **S√ç** | üî¥ ALTA |
| **PostgreSQL** | 10 + 20 pool | 30 conexiones | ‚ö†Ô∏è Si escalas Gunicorn | üü° MEDIA |
| **Redis** | 512MB | ~50k sesiones | ‚ùå No | üü¢ BAJA |
| **Celery** | 4 workers | 4 tareas async | ‚ö†Ô∏è Para tareas pesadas | üü¢ BAJA |

---

## üéØ Recomendaciones de Escalamiento

### Corto Plazo (Esta Semana)

#### 1. Aumentar Workers de Gunicorn

**Prioridad**: üî¥ CR√çTICA

```dockerfile
# Dockerfile:100 - Cambiar de:
CMD ["gunicorn", "--workers", "4", "--threads", "2", ...]

# A (para 4 cores):
CMD ["gunicorn", "--workers", "9", "--threads", "2", ...]

# O (para 8 cores):
CMD ["gunicorn", "--workers", "17", "--threads", "2", ...]
```

**Impacto**:
- Usuarios concurrentes: 200-400 ‚Üí 450-900 (125% aumento)
- Costo: M√≠nimo (solo m√°s RAM/CPU)

#### 2. Ajustar Pool de PostgreSQL

**Prioridad**: üü° MEDIA

```python
# app.py:140 - Para 9 workers:
"pool_size": 15,
"max_overflow": 30,  # Total: 45

# Para 17 workers:
"pool_size": 20,
"max_overflow": 40,  # Total: 60
```

#### 3. Mejorar Rate Limiting

**Prioridad**: üü° MEDIA

Implementar rate limiting diferenciado:

```python
# Ejemplo de mejora:
@limiter.limit("3 per minute", methods=["POST"])  # IP an√≥nima
@limiter.limit("30 per minute", methods=["POST"], key_func=lambda: f"user:{current_user.id}")  # Usuario autenticado
def register():
    ...
```

---

### Medio Plazo (Pr√≥ximo Mes)

#### 4. Implementar Caching Agresivo

**Prioridad**: üü° MEDIA

```python
from flask_caching import Cache

cache = Cache(app, config={
    'CACHE_TYPE': 'redis',
    'CACHE_REDIS_URL': 'redis://localhost:6379/3',
    'CACHE_DEFAULT_TIMEOUT': 300
})

@cache.cached(timeout=60, key_prefix='dashboard_data')
def get_dashboard_data():
    # Operaci√≥n costosa
    return data
```

**Impacto**: Reduce carga en DB hasta 80% para datos frecuentemente consultados.

#### 5. Optimizar Queries Lentas

**Prioridad**: üü° MEDIA

Identificar queries lentas:

```sql
-- En PostgreSQL
SELECT query, calls, mean_exec_time, max_exec_time
FROM pg_stat_statements
WHERE mean_exec_time > 100  -- >100ms
ORDER BY mean_exec_time DESC
LIMIT 20;
```

Agregar √≠ndices donde sea necesario.

---

### Largo Plazo (Pr√≥ximos 3-6 Meses)

#### 6. Escalamiento Horizontal

**Prioridad**: üü¢ BAJA (solo si >500 usuarios concurrentes)

Cuando un solo servidor ya no sea suficiente:

```yaml
# docker-compose.yml
services:
  app1:
    # Primer servidor Flask
  app2:
    # Segundo servidor Flask
  app3:
    # Tercer servidor Flask

  nginx:
    # Load balancer entre app1, app2, app3
```

**Nginx configuration**:
```nginx
upstream flask_backend {
    least_conn;
    server app1:5000;
    server app2:5000;
    server app3:5000;
}
```

**Impacto**: Escala linealmente con n√∫mero de servidores.

#### 7. CDN para Assets Est√°ticos

**Prioridad**: üü¢ BAJA

Usar CloudFlare, AWS CloudFront, o similar para servir:
- JavaScript, CSS
- Im√°genes
- PDFs generados

**Impacto**: Reduce carga en servidor Flask hasta 40%.

---

## üß™ Testing de Carga Recomendado

### Herramientas

1. **Locust** (Recomendado para Flask)
```python
# locustfile.py
from locust import HttpUser, task, between

class ObyraUser(HttpUser):
    wait_time = between(1, 3)

    @task(3)
    def view_dashboard(self):
        self.client.get("/reportes/dashboard")

    @task(1)
    def view_obras(self):
        self.client.get("/obras/lista")
```

Ejecutar:
```bash
locust -f locustfile.py --host=http://localhost:5002
```

2. **Apache Bench** (Para tests r√°pidos)
```bash
# Test simple de login
ab -n 1000 -c 10 -p login_data.txt -T application/x-www-form-urlencoded \
   http://localhost:5002/auth/login
```

3. **K6** (Para CI/CD)
```javascript
import http from 'k6/http';
import { check } from 'k6';

export let options = {
  stages: [
    { duration: '2m', target: 100 },  // Ramp up to 100 users
    { duration: '5m', target: 100 },  // Stay at 100 users
    { duration: '2m', target: 0 },    // Ramp down
  ],
};

export default function() {
  let res = http.get('http://localhost:5002/');
  check(res, { 'status was 200': (r) => r.status == 200 });
}
```

### M√©tricas a Monitorear

1. **Latencia**:
   - P50 (mediana): <200ms ‚úÖ
   - P95: <500ms ‚úÖ
   - P99: <1000ms ‚úÖ

2. **Throughput**:
   - Requests/segundo sin errores
   - Objetivo: >40 req/s con config actual

3. **Errores**:
   - HTTP 500: <0.1% ‚úÖ
   - HTTP 429 (rate limit): Depende del endpoint
   - Timeouts: <1% ‚úÖ

4. **Recursos**:
   - CPU: <80% promedio ‚úÖ
   - RAM: <80% de disponible ‚úÖ
   - DB connections: <70% del pool ‚úÖ

---

## üìù Conclusiones Finales

### Capacidad Actual

| Escenario | Usuarios Concurrentes | Configuraci√≥n Requerida |
|-----------|---------------------|------------------------|
| **Navegaci√≥n ligera** | ~300-400 usuarios | ‚úÖ Configuraci√≥n actual |
| **Uso normal (mix)** | ~200-300 usuarios | ‚úÖ Configuraci√≥n actual |
| **Operaciones pesadas** | ~50-100 usuarios | ‚úÖ Configuraci√≥n actual |

### Para Escalar a M√°s Usuarios

| Objetivo | Acci√≥n Requerida | Dificultad | Costo |
|----------|-----------------|------------|-------|
| **500-800 usuarios** | Aumentar Gunicorn workers a 9-17 | üü¢ F√°cil | üí∞ Bajo |
| **1000-2000 usuarios** | + PostgreSQL pool + Redis 1GB | üü° Medio | üí∞üí∞ Medio |
| **>2000 usuarios** | Escalamiento horizontal (m√∫ltiples servidores) | üî¥ Dif√≠cil | üí∞üí∞üí∞ Alto |

### Pr√≥ximos Pasos Inmediatos

1. ‚úÖ **Monitorear m√©tricas actuales** (CPU, RAM, response times)
2. ‚úÖ **Implementar testing de carga** con Locust
3. ‚úÖ **Aumentar Gunicorn workers** si CPU usage < 60%
4. ‚úÖ **Configurar alertas** para cuando se alcance 80% de capacidad

---

**√öltima actualizaci√≥n**: 2025-11-02
**Autor**: An√°lisis de Claude Code
**Pr√≥xima revisi√≥n**: Cuando se alcance 70% de capacidad actual
